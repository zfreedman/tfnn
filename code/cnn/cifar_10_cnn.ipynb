{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# cifar-10 cnn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "from sklearn.preprocessing import OneHotEncoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def unpickle(file):\n",
    "    with open(file, \"rb\") as f:\n",
    "        data_map = pickle.load(f, encoding=\"bytes\")\n",
    "    return data_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = unpickle(\"../my_datasets/cifar-10-batches-py/data_batch_1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 3072)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#10000 images, 1024 pixels (and 3 color channels, 1024 * 3)\n",
    "data[b\"data\"].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data[b\"data\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "images: 10000\n",
      "dimensions: [32, 32]\n",
      "pixels: 1024\n",
      "colors: 3\n"
     ]
    }
   ],
   "source": [
    "num_images = data[b\"data\"].shape[0]\n",
    "num_pixels = int(data[b\"data\"].shape[1] / 3)\n",
    "num_colors = 3\n",
    "img_dim = [int(num_pixels ** .5)] * 2\n",
    "print(\"images: {}\\ndimensions: {}\\npixels: {}\\ncolors: {}\".format(\n",
    "    num_images, img_dim, num_pixels, num_colors\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### reshaping the data\n",
    "We'll start by reshaping the 2nd dimension of each image to be of shape (3, 1024), where all red features are (0, ?), all green are (1, ?) and all blue are (2, ?). The shape of the entire dataset should afterwards be (10000, 1024, 3)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "features = np.asarray(\n",
    "    list(\n",
    "        map(\n",
    "            lambda img: [\n",
    "                [img[i], img[num_pixels + i], img[2*num_pixels + i]] for i in range(num_pixels)\n",
    "            ],\n",
    "            data[b\"data\"]\n",
    "        )\n",
    "    )\n",
    ")\n",
    "#).reshape(num_images, img_dim[0], img_dim[1], num_colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 1024, 3)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.imshow(reshaped_data[9])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## labels\n",
    "Below we'll one-hot encode the labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels = np.asarray(data[b\"labels\"])\n",
    "num_classes = np.unique(labels).shape[0]\n",
    "num_classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000,)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.,  0.,  0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  1.],\n",
       "       [ 0.,  0.,  0.,  0.,  1.,  0.,  0.,  0.,  0.,  0.],\n",
       "       [ 0.,  1.,  0.,  0.,  0.,  0.,  0.,  0.,  0.,  0.]])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#one-hot encoding\n",
    "y_true = OneHotEncoder().fit_transform(labels.reshape(-1, 1)).toarray()\n",
    "y_true[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## network setup\n",
    "Below we'll setup the network. We'll create a 2 layer convolution (each with a max pooling layer) connected to 2 dense layers. This model is based on the TensorFlow [CNN tutorial](https://www.tensorflow.org/tutorials/layers)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "placeholders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = tf.placeholder(dtype=tf.float32, shape=[None, num_pixels])\n",
    "y = tf.placeholder(dtype=tf.float32, shape=[None, num_classes])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_layer = tf.reshape(x, [-1, img_dim[0], img_dim[1], num_colors])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### convolution parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convolution\n",
    "filters = [32, 64]\n",
    "kernel_sizes = [[5, 5], [5, 5]]\n",
    "paddings = [\"same\", \"same\"]\n",
    "activations = [tf.nn.relu, tf.nn.relu]\n",
    "\n",
    "#pooling\n",
    "pool_sizes = [[2, 2], [2, 2]]\n",
    "strides = [2, 2]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convolution 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convolution\n",
    "conv0 = tf.layers.conv2d(\n",
    "    inputs=input_layer,\n",
    "    filters=filters[0],\n",
    "    kernel_size=kernel_sizes[0],\n",
    "    padding=paddings[0],\n",
    "    activation=activations[0]\n",
    ")\n",
    "#pool\n",
    "pool0 = tf.layers.max_pooling2d(\n",
    "    inputs=conv0,\n",
    "    pool_size=pool_sizes[0],\n",
    "    strides=strides[0]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "convolution 1\n",
    "\n",
    "Notice that with this structure, the convolutional portion of the network is easily refactorable into a loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#convolution\n",
    "conv1 = tf.layers.conv2d(\n",
    "    inputs=pool0,\n",
    "    filters=filters[1],\n",
    "    kernel_size=kernel_sizes[1],\n",
    "    padding=paddings[1],\n",
    "    activation=activations[1]\n",
    ")\n",
    "#pool\n",
    "pool1 = tf.layers.max_pooling2d(\n",
    "    inputs=conv1,\n",
    "    pool_size=pool_sizes[1],\n",
    "    strides=strides[1]\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "flatten"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[8, 8]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "resulting_img_dim = img_dim[:]\n",
    "for p in pool_sizes:\n",
    "    for j in range(2):\n",
    "        resulting_img_dim[j] = int(resulting_img_dim[j] / p[j])\n",
    "resulting_img_dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "conv_flat = tf.reshape(tensor=pool1, shape=[-1, resulting_img_dim[0] * resulting_img_dim[1] * filters[1]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "dense 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#seems like units choice is open to interpretation\n",
    "drop_rate = tf.placeholder(tf.float32, shape=[1])\n",
    "dense0 = tf.layers.dense(inputs=conv_flat, units=1024, activation=tf.nn.relu)\n",
    "dropout0 = tf.layers.dropout(inputs=dense0, rate=drop_rate)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "logits (y probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "logits = tf.layers.dense(inputs=dropout0, units=num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "loss = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(\n",
    "    labels=labels,\n",
    "    logits=logits\n",
    "))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## hyperparams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = 0.001\n",
    "epochs = 300\n",
    "batch_size = 16\n",
    "dropout_prob_train = 0.5\n",
    "dropout_prob_test = 1.0\n",
    "epochs_between_output = 20"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "optimizer = tf.trace"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
